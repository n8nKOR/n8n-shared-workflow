{
  "meta": {
    "instanceId": "408f9fb9940c3cb18ffdef0e0150fe342d6e655c3a9fac21f0f644e8bedabcd9",
    "templateCredsSetupCompleted": true
  },
  "nodes": [
    {
      "id": "27e5f0c0-ba88-4c28-b3be-99c973be15cb",
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -480,
        -140
      ],
      "parameters": {
        "width": 1083,
        "height": 357,
        "content": "## 이것은 기본 LLM 체인이 오픈소스 모델에 연결된 예입니다  \n### 체인은 Mistral-7B-Instruct-v0.1 모델에 연결되어 있지만, 변경할 수 있습니다  \n\n모델을 안내하는 초기 프롬프트를 주의 깊게 보세요:  \n```  \n당신은 도움이 되는 어시스턴트입니다.  \n사용자들에게 예의 바르게 답변하세요.  \n이모지와 텍스트를 사용하세요.  \nQ: {{ $json.input }}  \nA:   \n```  \n\n이 방법으로 모델은 `A: ` 바로 후에 질문을 답변해야 한다는 것을 \"알아\"요.  \n\nHugging Face 노드가 추론 모드이기 때문에, 현재 LangChain Agents를 지원하지 않습니다. 이를 위해 [Ollama Chat Model](https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatollama/) 노드를 사용하세요"
      },
      "typeVersion": 1
    },
    {
      "id": "4756d5a8-7027-4942-b214-a5ff8310869a",
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "position": [
        -200,
        280
      ],
      "webhookId": "bf2e38b8-566a-4aeb-8efe-28240f4a6991",
      "parameters": {
        "options": {}
      },
      "typeVersion": 1.1
    },
    {
      "id": "20a36351-8579-4ac6-9746-526b072aeaa6",
      "name": "Basic LLM Chain",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "position": [
        20,
        280
      ],
      "parameters": {
        "messages": {
          "messageValues": [
            {
              "message": "=You are a helpful assistant. Please reply politely to the users. Use emojis and a text."
            }
          ]
        }
      },
      "typeVersion": 1.5
    },
    {
      "id": "9b88e307-3ad5-4167-8c5f-e5827f7444ac",
      "name": "Hugging Face Inference Model",
      "type": "@n8n/n8n-nodes-langchain.lmOpenHuggingFaceInference",
      "position": [
        120,
        440
      ],
      "parameters": {
        "model": "mistralai/Mistral-7B-Instruct-v0.1",
        "options": {
          "maxTokens": 512,
          "temperature": 0.8,
          "frequencyPenalty": 2
        }
      },
      "credentials": {
        "huggingFaceApi": {
          "id": "ARQ5mOhvBxi283Qk",
          "name": "HuggingFaceApi account"
        }
      },
      "typeVersion": 1
    }
  ],
  "pinData": {},
  "connections": {
    "When chat message received": {
      "main": [
        [
          {
            "node": "Basic LLM Chain",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Hugging Face Inference Model": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    }
  }
}