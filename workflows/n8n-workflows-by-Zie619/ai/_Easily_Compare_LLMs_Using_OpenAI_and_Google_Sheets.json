{
  "id": "",
  "meta": {
    "instanceId": "",
    "templateCredsSetupCompleted": true
  },
  "name": "Easily Compare LLMs Using OpenAI and Google Sheets",
  "tags": [],
  "nodes": [
    {
      "id": "",
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "position": [
        -7400,
        3040
      ],
      "webhookId": "",
      "parameters": {
        "options": {}
      },
      "typeVersion": 1.1
    },
    {
      "id": "",
      "name": "Loop Over Items",
      "type": "n8n-nodes-base.splitInBatches",
      "position": [
        -5960,
        3040
      ],
      "parameters": {
        "options": {
          "reset": false
        }
      },
      "typeVersion": 3
    },
    {
      "id": "",
      "name": "Simple Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "position": [
        -4880,
        3000
      ],
      "parameters": {
        "sessionKey": "={{$('Set model, sessionId, chatInput, sessionIdBase').item.json.sessionId}}",
        "sessionIdType": "customKey"
      },
      "typeVersion": 1.3
    },
    {
      "id": "",
      "name": "Chat Memory Manager",
      "type": "@n8n/n8n-nodes-langchain.memoryManager",
      "position": [
        -4980,
        3180
      ],
      "parameters": {
        "options": {}
      },
      "typeVersion": 1.1
    },
    {
      "id": "",
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -8120,
        2600
      ],
      "parameters": {
        "color": 5,
        "width": 640,
        "height": 1180,
        "content": "## LLM을 OpenAI와 Google Sheets를 사용하여 쉽게 비교하세요\n\n이 워크플로우를 통해 **두 개의 언어 모델(LLM)의 출력을 쉽게 평가하고 비교**할 수 있어, 프로덕션에 사용할 하나를 선택하기 전에 도움이 됩니다.\n\n채팅 인터페이스에서 두 모델의 출력이 나란히 표시됩니다. 이 응답들은 Google Sheets에 기록되며, 여기서 수동으로 또는 고급 모델을 사용하여 자동으로 평가할 수 있습니다.\n\n### 사용 사례\nAI 에이전트를 개발 중이며, LLM이 비결정적이기 때문에 특정 용도에 가장 적합한 모델을 결정하고 싶을 때입니다. 이 템플릿은 효과적으로 비교할 수 있도록 설계되었습니다.\n\n### 작동 원리\n- 사용자가 채팅 인터페이스에 메시지를 보냅니다.\n- 입력이 복제되어 두 개의 서로 다른 LLM으로 전송됩니다.\n- 각 모델이 동일한 프롬프트를 독립적으로 처리하며, 자체 메모리 컨텍스트를 사용합니다.\n- 그들의 답변, 사용자 입력, 이전 컨텍스트가 Google Sheets에 기록됩니다.\n- 모델 출력물을 수동으로 검토, 비교, 평가할 수 있으며(나중에 자동화 가능).\n- 채팅에서 두 응답이 연속적으로 표시되어 직접 비교할 수 있습니다.\n\n### 사용 방법\n- 이 [Google Sheets 템플릿](https://docs.google.com/spreadsheets/d/1grO5jxm05kJ7if9wBIOozjkqW27i8tRedrheLRrpxf4/)을 복사합니다 (파일 > 복사본 만들기).\n- **AI Agent** 노드에서 **System Prompt**와 **Tools**를 귀하의 용도에 맞게 설정합니다.\n- 채팅을 시작하세요! 각 메시지가 두 모델을 트리거하고 그 응답을 스프레드시트에 기록합니다.\n\n*참고: 이 버전은 두 모델을 위한 것입니다. 더 많은 모델을 비교하려면 워크플로우 로직을 확장하고 시트를 업데이트해야 합니다.*\n\n### 모델 정보\n**OpenRouter** 또는 **Vertex AI**를 사용하여 여러 제공업체의 모델을 테스트할 수 있습니다.  \n특정 제공업체의 노드를 사용하는 경우, 예를 들어 OpenAI를 사용하면 그 제공업체의 다른 모델을 비교할 수 있습니다 (예: `gpt-4` vs `gpt-4o-mini`).\n\n### Google Sheets에서의 평가\n이 기능은 팀에 이상적이며, 데이터 과학자뿐만 아니라 비기술적 이해관계자들이 실생활 요구사항에 기반하여 응답을 평가할 수 있습니다.\n\n고급 사용자는 더 강력한 모델 (예: **OpenAI**의 `o1` 또는 `o3`)을 사용하여 평가를 자동화할 수 있지만, 이는 토큰 사용량과 비용을 증가시킬 수 있습니다.\n\n### 토큰 고려사항\n**각 입력이 두 개의 서로 다른 모델에 의해 처리되기 때문에** 전체적으로 더 많은 토큰이 소비됩니다.  \n더 긴 프롬프트나 여러 평가를 실행하는 경우 사용량을 주의 깊게 모니터링하세요, 이는 비용에 영향을 미칠 수 있습니다."
      },
      "typeVersion": 1
    },
    {
      "id": "",
      "name": "OpenRouter Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "position": [
        -5180,
        3000
      ],
      "parameters": {
        "model": "={{$json.model}}"
      },
      "credentials": {
        "openRouterApi": {
          "id": "",
          "name": ""
        }
      },
      "typeVersion": 1
    },
    {
      "id": "",
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -7220,
        2620
      ],
      "parameters": {
        "color": 7,
        "width": 360,
        "height": 580,
        "content": "## 비교할 모델 정의\n\n이 노드는 비교할 모델 ID의 배열을 정의합니다.\n\n이 템플릿에서 OpenRouter API를 사용하여 두 개의 모델을 비교합니다. 테스트하고 싶은 전체 모델 ID를 지정하여 목록을 수정할 수 있습니다.\n\n예시:\n**[\"openai/gpt-4.1\", \"mistralai/mistral-large\"]**\n\n다른 LLM 제공자(예: OpenAI 직접, 또는 Google Vertex AI)를 사용 중이라면, 해당 제공자의 명명 규칙에 따라 모델 ID를 업데이트하세요.\n\n*노트: 이 템플릿은 두 개의 모델을 위해 만들어졌습니다. 더 많은 모델의 경우, 워크플로우 로직과 Google Sheet 구조를 조정해야 합니다.*"
      },
      "typeVersion": 1
    },
    {
      "id": "",
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -6500,
        2620
      ],
      "parameters": {
        "color": 7,
        "width": 360,
        "height": 580,
        "content": "## 모델, sessionId, chatInput, sessionIdBase 설정\n\n이 노드는 각 모델을 쿼리하는 루프 동안 사용되는 변수를 준비합니다.\n\n- **model**: 현재 반복에서 사용되는 모델의 ID.\n- **sessionId**: 원래 세션 ID와 모델 이름을 결합한 고유 세션 키. 이는 모델별 메모리 격리를 보장합니다.\n- **chatInput**: 사용자의 입력 메시지.\n- **sessionIdBase**: 모델에 특정한 접미사가 없는 원래 세션 ID. Sheets에서 동일한 세션의 평가를 그룹화하는 데 사용됩니다."
      },
      "typeVersion": 1
    },
    {
      "id": "",
      "name": "Set model, sessionId, chatInput, sessionIdBase",
      "type": "n8n-nodes-base.set",
      "position": [
        -6380,
        3040
      ],
      "parameters": {
        "options": {},
        "assignments": {
          "assignments": [
            {
              "id": "",
              "name": "model",
              "type": "string",
              "value": "={{ $json.models }}"
            },
            {
              "id": "",
              "name": "sessionId",
              "type": "string",
              "value": "={{ $('When chat message received').item.json.sessionId }}{{$json.models }}"
            },
            {
              "id": "",
              "name": "chatInput",
              "type": "string",
              "value": "={{ $('When chat message received').item.json.chatInput }}"
            },
            {
              "id": "",
              "name": "sessionIdBase",
              "type": "string",
              "value": "={{ $('When chat message received').item.json.sessionId }}"
            }
          ]
        }
      },
      "typeVersion": 3.4
    },
    {
      "id": "",
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [
        -5480,
        3180
      ],
      "parameters": {
        "options": {
          "returnIntermediateSteps": false
        }
      },
      "typeVersion": 1.8
    },
    {
      "id": "",
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -5600,
        3160
      ],
      "parameters": {
        "color": 7,
        "width": 540,
        "height": 520,
        "content": "## AI 에이전트\n\n이 AI 에이전트는 OpenRouter 모델에 연결되어 있습니다. 모델은 이전에 정의된 변수 `{{$json.model}}`에서 동적으로 선택됩니다.\n\n메모리는 `{{$('Set model, sessionId, chatInput, sessionIdBase').item.json.sessionId}}` 키를 사용하여 모델별로 격리됩니다.\n\n**⚠️ 이 에이전트에는 현재 시스템 프롬프트나 도구가 구성되어 있지 않습니다**. 특정 작업을 테스트하려면, 현실적인 사용 사례를 반영하도록 직접 정의해야 합니다.\n\n### 출력"
      },
      "typeVersion": 1
    },
    {
      "id": "",
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -5040,
        3160
      ],
      "parameters": {
        "color": 7,
        "width": 380,
        "height": 520,
        "content": "## 채팅 메모리 관리자\n\n이 노드는 채팅 세션의 이전 맥락 검색을 처리합니다. Google Sheet에 주입된 맥락을 저장하여 질적 평가를 돕습니다.\n\nAI 에이전트와 “Simple Memory” 노드를 통해 메모리를 공유합니다.\n\n> 필요시 Redis 또는 Postgres 메모리 백엔드로 전환할 수 있습니다.\n\n### 출력"
      },
      "typeVersion": 1
    },
    {
      "id": "",
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -4640,
        3160
      ],
      "parameters": {
        "color": 7,
        "width": 380,
        "height": 760,
        "content": "## 채팅 및 Google Sheets용 데이터 준비\n\n이 노드는 다음 필드를 설정합니다:\n\n- **output**: 모델의 응답으로, 채팅 표시를 위해 시각적 구분을 추가하여 비교를 쉽게 함.\n- **chatInput**: Google Sheets에 기록될 사용자 입력.\n- **model_answer**: 평가 중인 모델의 실제 답변.\n- **model**: 답변을 제공하는 모델의 이름 또는 ID로, 성능 식별에 사용됨.\n- **context**: 이전 대화 기록(최신 입력 제외). 사용자의 첫 번째 메시지인 경우 플레이스홀더가 사용됨.\n- **sessionId**: 모델 이름과 세션을 결합한 고유 세션 식별자, 각 모델에 대한 별도의 컨텍스트 창을 보장함.\n- **sessionIdBase**: 모델 접미사 없이 원래 사용자 세션 ID로, Sheets에서 다양한 모델의 응답을 그룹화하는 데 유용함.\n\n### 출력"
      },
      "typeVersion": 1
    },
    {
      "id": "",
      "name": "Concatenate Chat Answers",
      "type": "n8n-nodes-base.summarize",
      "position": [
        -5300,
        2620
      ],
      "parameters": {
        "options": {},
        "fieldsToSummarize": {
          "values": [
            {
              "field": "output",
              "separateBy": "\n",
              "aggregation": "concatenate"
            }
          ]
        }
      },
      "typeVersion": 1.1
    },
    {
      "id": "",
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -5080,
        2120
      ],
      "parameters": {
        "color": 5,
        "width": 460,
        "height": 500,
        "content": "## 모델 결과 Google 시트에 추가\n\n이 Google Sheets 단계는 모델 응답을 평가를 위해 기록합니다.\n\n⚠️ 모델 응답의 길이에 따라 행 높이 또는 열 너비를 조정해야 할 수 있습니다.\n\n템플릿에는 기본 평가 필드(`model_1_eval`, `model_2_eval`)가 포함되어 있으며, 드롭다운에 **\"Good\", \"Correct\", \"Bad\"**와 같은 항목이 있습니다. 하지만 더 세부적인 평가 기준으로 자유롭게 커스터마이즈하세요."
      },
      "typeVersion": 1
    },
    {
      "id": "",
      "name": "Group Model Outputs for Evaluation",
      "type": "n8n-nodes-base.aggregate",
      "position": [
        -5300,
        2440
      ],
      "parameters": {
        "options": {},
        "fieldsToAggregate": {
          "fieldToAggregate": [
            {
              "fieldToAggregate": "model_answer"
            },
            {
              "fieldToAggregate": "context"
            },
            {
              "fieldToAggregate": "chatInput"
            },
            {
              "fieldToAggregate": "sessionIdBase"
            },
            {
              "fieldToAggregate": "model"
            }
          ]
        }
      },
      "typeVersion": 1
    },
    {
      "id": "",
      "name": "Add Model Results to Google Sheet",
      "type": "n8n-nodes-base.googleSheets",
      "onError": "continueRegularOutput",
      "position": [
        -4940,
        2440
      ],
      "parameters": {
        "columns": {
          "value": {
            "sessionId": "={{ $json.sessionIdBase[0] }}",
            "model_1_id": "={{ $json.model[0] }}",
            "model_2_id": "={{ $json.model[1] }}",
            "user_input": "={{ $json.chatInput[0] }}",
            "model_1_answer": "={{ $json.model_answer[0] }}",
            "model_2_answer": "={{ $json.model_answer[1] }}",
            "context_model_1": "={{ $json.context[0] }}",
            "context_model_2": "={{ $json.context[1] }}"
          },
          "schema": [
            {
              "id": "sessionId",
              "type": "string",
              "display": true,
              "required": false,
              "displayName": "sessionId",
              "defaultMatch": false,
              "canBeUsedToMatch": true
            },
            {
              "id": "model_1_id",
              "type": "string",
              "display": true,
              "required": false,
              "displayName": "model_1_id",
              "defaultMatch": false,
              "canBeUsedToMatch": true
            },
            {
              "id": "model_2_id",
              "type": "string",
              "display": true,
              "required": false,
              "displayName": "model_2_id",
              "defaultMatch": false,
              "canBeUsedToMatch": true
            },
            {
              "id": "user_input",
              "type": "string",
              "display": true,
              "required": false,
              "displayName": "user_input",
              "defaultMatch": false,
              "canBeUsedToMatch": true
            },
            {
              "id": "model_1_answer",
              "type": "string",
              "display": true,
              "required": false,
              "displayName": "model_1_answer",
              "defaultMatch": false,
              "canBeUsedToMatch": true
            },
            {
              "id": "model_2_answer",
              "type": "string",
              "display": true,
              "required": false,
              "displayName": "model_2_answer",
              "defaultMatch": false,
              "canBeUsedToMatch": true
            },
            {
              "id": "model_1_eval",
              "type": "string",
              "display": true,
              "required": false,
              "displayName": "model_1_eval",
              "defaultMatch": false,
              "canBeUsedToMatch": true
            },
            {
              "id": "model_2_eval",
              "type": "string",
              "display": true,
              "required": false,
              "displayName": "model_2_eval",
              "defaultMatch": false,
              "canBeUsedToMatch": true
            },
            {
              "id": "context_model_1",
              "type": "string",
              "display": true,
              "required": false,
              "displayName": "context_model_1",
              "defaultMatch": false,
              "canBeUsedToMatch": true
            },
            {
              "id": "context_model_2",
              "type": "string",
              "display": true,
              "required": false,
              "displayName": "context_model_2",
              "defaultMatch": false,
              "canBeUsedToMatch": true
            }
          ],
          "mappingMode": "defineBelow",
          "matchingColumns": [],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        },
        "options": {},
        "operation": "append",
        "sheetName": {
          "__rl": true,
          "mode": "list",
          "value": "gid=0",
          "cachedResultUrl": "https://docs.google.com/spreadsheets/d/1grO5jxm05kJ7if9wBIOozjkqW27i8tRedrheLRrpxf4/",
          "cachedResultName": "llms_eval"
        },
        "documentId": {
          "__rl": true,
          "mode": "list",
          "value": "1grO5jxm05kJ7if9wBIOozjkqW27i8tRedrheLRrpxf4",
          "cachedResultUrl": "https://docs.google.com/spreadsheets/d/1grO5jxm05kJ7if9wBIOozjkqW27i8tRedrheLRrpxf4/",
          "cachedResultName": "Template - Easy LLMs Eval"
        },
        "authentication": "serviceAccount"
      },
      "credentials": {
        "googleApi": {
          "id": "",
          "name": ""
        }
      },
      "typeVersion": 4.5
    },
    {
      "id": "",
      "name": "Prepare Data for Chat and Google Sheets",
      "type": "n8n-nodes-base.set",
      "position": [
        -4500,
        3180
      ],
      "parameters": {
        "options": {},
        "assignments": {
          "assignments": [
            {
              "id": "",
              "name": "output",
              "type": "string",
              "value": "=### `{{ $('Set model, sessionId, chatInput, sessionIdBase').item.json.model }}` answered :\n\n\n{{ $('AI Agent').item.json.output }}\n\n----------\n"
            },
            {
              "id": "",
              "name": "chatInput",
              "type": "string",
              "value": "={{ $('Set model, sessionId, chatInput, sessionIdBase').item.json.chatInput }}"
            },
            {
              "id": "",
              "name": "model_answer",
              "type": "string",
              "value": "={{ $('AI Agent').item.json.output }}"
            },
            {
              "id": "",
              "name": "model",
              "type": "string",
              "value": "={{ $('Set model, sessionId, chatInput, sessionIdBase').item.json.model }}"
            },
            {
              "id": "",
              "name": "context",
              "type": "string",
              "value": "={{\n  (() => {\n    const history = $json[\"messages\"]; // ou adapter selon ton chemin réel\n    if (!Array.isArray(history) || history.length <= 1) {\n      return \"No prior context available — likely the user's first message or memory not yet initialized.\";\n    }\n\n    const truncated = history.slice(0, -1); // on enlève le dernier échange\n    return truncated.map(pair => `Human: ${pair.human}\\nAI: ${pair.ai}`).join('\\n');\n  })()\n}}\n"
            },
            {
              "id": "",
              "name": "sessionId",
              "type": "string",
              "value": "={{ $('Loop Over Items').item.json.sessionId }}"
            },
            {
              "id": "",
              "name": "sessionIdBase",
              "type": "string",
              "value": "={{ $('Loop Over Items').item.json.sessionIdBase }}"
            }
          ]
        }
      },
      "typeVersion": 3.4
    },
    {
      "id": "",
      "name": "Define Models to Compare",
      "type": "n8n-nodes-base.set",
      "position": [
        -7100,
        3040
      ],
      "parameters": {
        "options": {},
        "assignments": {
          "assignments": [
            {
              "id": "",
              "name": "=models",
              "type": "array",
              "value": "=[\"openai/gpt-4.1\", \"mistralai/mistral-large\"]"
            }
          ]
        }
      },
      "typeVersion": 3.4
    },
    {
      "id": "",
      "name": "Split Models into Items",
      "type": "n8n-nodes-base.splitOut",
      "position": [
        -6760,
        3040
      ],
      "parameters": {
        "options": {},
        "fieldToSplitOut": "models"
      },
      "typeVersion": 1
    },
    {
      "id": "",
      "name": "Set Output for Chat UI",
      "type": "n8n-nodes-base.set",
      "position": [
        -4940,
        2620
      ],
      "parameters": {
        "options": {},
        "assignments": {
          "assignments": [
            {
              "id": "",
              "name": "output",
              "type": "string",
              "value": "={{ $json.concatenated_output }}"
            }
          ]
        }
      },
      "typeVersion": 3.4
    }
  ],
  "active": false,
  "pinData": {},
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "",
  "connections": {
    "AI Agent": {
      "main": [
        [
          {
            "node": "Chat Memory Manager",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Simple Memory": {
      "ai_memory": [
        [
          {
            "node": "Chat Memory Manager",
            "type": "ai_memory",
            "index": 0
          },
          {
            "node": "AI Agent",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "Loop Over Items": {
      "main": [
        [
          {
            "node": "Concatenate Chat Answers",
            "type": "main",
            "index": 0
          },
          {
            "node": "Group Model Outputs for Evaluation",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Chat Memory Manager": {
      "main": [
        [
          {
            "node": "Prepare Data for Chat and Google Sheets",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenRouter Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Split Models into Items": {
      "main": [
        [
          {
            "node": "Set model, sessionId, chatInput, sessionIdBase",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Concatenate Chat Answers": {
      "main": [
        [
          {
            "node": "Set Output for Chat UI",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Define Models to Compare": {
      "main": [
        [
          {
            "node": "Split Models into Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "When chat message received": {
      "main": [
        [
          {
            "node": "Define Models to Compare",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Group Model Outputs for Evaluation": {
      "main": [
        [
          {
            "node": "Add Model Results to Google Sheet",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Data for Chat and Google Sheets": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Set model, sessionId, chatInput, sessionIdBase": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  }
}